import ollama
import os
import xml.etree.ElementTree as ET
from itertools import combinations

def read_bpmn_file(file_path):
    """Reads the XML content of a BPMN file."""
    with open(file_path, 'r', encoding='utf-8') as file:
        return file.read()

def extract_task_names(file_path):
    """Extracts task names from a BPMN file."""
    tree = ET.parse(file_path)
    root = tree.getroot()
    ns = {'bpmn': 'http://www.omg.org/spec/BPMN/20100524/MODEL'}

    task_names = []
    for task_type in ['task', 'userTask', 'manualTask', 'serviceTask', 'scriptTask', 
                      'businessRuleTask', 'sendTask', 'receiveTask', 'callActivity']:
        for task in root.findall(f".//bpmn:{task_type}", ns):
            name = task.attrib.get('name')
            if name:
                task_names.append(name)
    return task_names

def compare_bpmn_files(file1_path, file2_path):
    """Compares two BPMN models using Llama 3 with the detailed prompt."""
    name_1 = os.path.basename(file1_path)
    name_2 = os.path.basename(file2_path)

    tasks1 = extract_task_names(file1_path)
    tasks2 = extract_task_names(file2_path)

    prompt = f"""
# Context and Role Specification 
You are a process analysis expert specialized in BPMN comparison, process similarity, and model alignment.

# Scope and Task Definition 
Compare two BPMN models and identify correspondences (mappings) between their components.
Then perform a structured self-critique and correction phase before producing final metrics.

Input:
BPMN Model 1: {name_1}
{chr(10).join(tasks1)}

BPMN Model 2: {name_2}
{chr(10).join(tasks2)}

# Procedure Design and Output Structuring 
1) Identify all 1:1 correspondences between elements of the two models.
2) For each mapping, compute a similarity score (0â€“1) using lexical, semantic, and functional resemblance.
3) Classify each mapping as:
   - VB (Verbatim): similarity > 0.90
   - MC (Modified Copy): similarity 0.65â€“0.90
   - HR (High Revision): similarity < 0.65
4) Output mappings grouped by category (VB first, then MC, then HR), with short justifications.
5) Perform a self-critique and correction phase:
   - Identify potential misclassifications, ambiguous tasks, or missing elements.
   - Propose corrected mappings if necessary.
6) Conclude with final metrics:
   - Total tasks in each model
   - Count and percentage of VB, MC, HR
   - Ambiguous, duplicated, or missing tasks
   - Global similarity score (weighted average of mapping similarities)

# Output format:
A) Initial mappings (VB â†’ MC â†’ HR)
B) Self-critique and revised mappings
C) Final metrics and global similarity

Return the complete structured analysis in English.
"""

    response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])
    
    # Print the result
    print(f"\n=== Comparison: {name_1} vs {name_2} ===\n")
    print(response['message']['content'])
    print("\n" + "="*80 + "\n")

def batch_compare_bpmn_files(bpmn_files):
    """Compares all combinations of BPMN files in the list."""
    for file1, file2 in combinations(bpmn_files, 2):
        try:
            compare_bpmn_files(file1, file2)
        except FileNotFoundError as e:
            print(f"File not found: {e}")
        except Exception as e:
            print(f"Error comparing {file1} vs {file2}: {e}")

# ðŸ‘‡ List all your BPMN files here
bpmn_files = [
    "Cologne.bpmn",
    "Frankfurt.bpmn",
    "IIS_Erlangen.bpmn",
    "Fu_Berlin.bpmn",
    "Hohenheim.bpmn",
    "Potsdam.bpmn",
    "Muenster.bpmn",
    "Tu_Munich.bpmn",
    "Wuerzburg.bpmn"
]

# Run comparisons for all pairs
batch_compare_bpmn_files(bpmn_files)
